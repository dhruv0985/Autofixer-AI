PS C:\Users\Asus\Desktop\autofixer> .\autofixer-env\Scripts\activate
>> 
(autofixer-env) PS C:\Users\Asus\Desktop\autofixer> embed_function.py
embed_function.py : The term 'embed_function.py' is not recognized as the name of a cmdlet, function, script file, or operable program. Check the spelling of the name, or if a 
path was included, verify that the path is correct and try again.
At line:1 char:1
+ embed_function.py
+ ~~~~~~~~~~~~~~~~~
    + CategoryInfo          : ObjectNotFound: (embed_function.py:String) [], CommandNotFoundException
    + FullyQualifiedErrorId : CommandNotFoundException
 

Suggestion [3,General]: The command embed_function.py was not found, but does exist in the current location. Windows PowerShell does not load commands from the current location by default. If you trust this command, instead type: ".\embed_function.py". See "get-help about_Command_Precedence" for more details.
(autofixer-env) PS C:\Users\Asus\Desktop\autofixer> cd ..
(autofixer-env) PS C:\Users\Asus\Desktop> cd .\autofixer\   
(autofixer-env) PS C:\Users\Asus\Desktop\autofixer> embed_function.py
embed_function.py : The term 'embed_function.py' is not recognized as the name of a cmdlet, function, script file, or operable program. Check the spelling of the name, or if a 
path was included, verify that the path is correct and try again.
At line:1 char:1
+ embed_function.py
+ ~~~~~~~~~~~~~~~~~
    + CategoryInfo          : ObjectNotFound: (embed_function.py:String) [], CommandNotFoundException
    + FullyQualifiedErrorId : CommandNotFoundException


Suggestion [3,General]: The command embed_function.py was not found, but does exist in the current location. Windows PowerShell does not load commands from the current location by default. If you trust this command, instead type: ".\embed_function.py". See "get-help about_Command_Precedence" for more details.
(autofixer-env) PS C:\Users\Asus\Desktop\autofixer> cd .\autofixer-env\        
(autofixer-env) PS C:\Users\Asus\Desktop\autofixer\autofixer-env> cd .
(autofixer-env) PS C:\Users\Asus\Desktop\autofixer\autofixer-env> cd ..
(autofixer-env) PS C:\Users\Asus\Desktop\autofixer> python embed_functions.py
>>
C:\Users\Asus\Desktop\autofixer\autofixer-env\Scripts\python.exe: can't open file 'C:\\Users\\Asus\\Desktop\\autofixer\\embed_functions.py': [Errno 2] No such file or directory
(autofixer-env) PS C:\Users\Asus\Desktop\autofixer> pwd

Path
----
C:\Users\Asus\Desktop\autofixer


(autofixer-env) PS C:\Users\Asus\Desktop\autofixer> dir


    Directory: C:\Users\Asus\Desktop\autofixer


Mode                 LastWriteTime         Length Name
----                 -------------         ------ ----
d-----        01-07-2025     18:38                autofixer-env
-a----        01-07-2025     19:14           2138 embed_function.py
-a----        01-07-2025     19:15            159 sample.py


(autofixer-env) PS C:\Users\Asus\Desktop\autofixer> python embed_function.py 
>> 
modules.json: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 349/349 [00:00<00:00, 2.46MB/s]
C:\Users\Asus\Desktop\autofixer\autofixer-env\Lib\site-packages\huggingface_hub\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\Users\Asus\.cache\huggingface\hub\models--sentence-transformers--all-MiniLM-L6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.
To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development
  warnings.warn(message)
config_sentence_transformers.json: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 116/116 [00:00<00:00, 737kB/s]
README.md: 10.5kB [00:00, 27.3MB/s]
sentence_bert_config.json: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 53.0/53.0 [00:00<00:00, 194kB/s]
config.json: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 612/612 [00:00<00:00, 5.45MB/s]
Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`
model.safetensors: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 90.9M/90.9M [00:27<00:00, 3.28MB/s]
tokenizer_config.json: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 350/350 [00:00<00:00, 1.34MB/s]
vocab.txt: 232kB [00:00, 4.80MB/s]
tokenizer.json: 466kB [00:00, 11.7MB/s]
special_tokens_map.json: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 112/112 [00:00<00:00, 1.09MB/s]
config.json: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 190/190 [00:00<00:00, 1.95MB/s]
Traceback (most recent call last):
  File "C:\Users\Asus\Desktop\autofixer\embed_function.py", line 63, in <module>
    embed_and_store(funcs)
    ~~~~~~~~~~~~~~~^^^^^^^
  File "C:\Users\Asus\Desktop\autofixer\embed_function.py", line 35, in embed_and_store
    index = faiss.IndexFlatL2(len(vectors[0]))
                                  ~~~~~~~^^^
IndexError: index 0 is out of bounds for axis 0 with size 0
(autofixer-env) PS C:\Users\Asus\Desktop\autofixer> python embed_function.py
>>
Indexed 2 functions from the file.
Results for query: 'save user preferences'

1. Function Name: save_preferences
def save_preferences(prefs):
    with open("prefs.json", "w") as f:
        json.dump(prefs, f)
————————————————————————————————————————
2. Function Name: greet
def greet(name):
    print(f"Hello, {name}")
————————————————————————————————————————
3. Function Name: save_preferences
def save_preferences(prefs):
    with open("prefs.json", "w") as f:
        json.dump(prefs, f)
————————————————————————————————————————
(autofixer-env) PS C:\Users\Asus\Desktop\autofixer> python embed_function.py
>>
Folder 'autofixer' not found.
(autofixer-env) PS C:\Users\Asus\Desktop\autofixer> python embed_function.py
>>
  File "C:\Users\Asus\Desktop\autofixer\embed_function.py", line 85
    folder_path = "C:\Users\Asus\Desktop\autofixer"  
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
SyntaxError: (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \UXXXXXXXX escape
(autofixer-env) PS C:\Users\Asus\Desktop\autofixer> python embed_function.py
>>
Failed to extract from C:\Users\Asus\Desktop\autofixer\autofixer-env\Lib\site-packages\joblib\test\test_func_inspect_special_encoding.py: 'utf-8' codec can't decode byte 0xa4 in position 64: invalid start byte
Traceback (most recent call last):
  File "C:\Users\Asus\Desktop\autofixer\embed_function.py", line 103, in <module>
    embed_and_store(funcs)
    ~~~~~~~~~~~~~~~^^^^^^^
  File "C:\Users\Asus\Desktop\autofixer\embed_function.py", line 63, in embed_and_store
    vectors = model.encode(function_text, convert_to_tensor=False)
  File "C:\Users\Asus\Desktop\autofixer\autofixer-env\Lib\site-packages\torch\utils\_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "C:\Users\Asus\Desktop\autofixer\autofixer-env\Lib\site-packages\sentence_transformers\SentenceTransformer.py", line 1052, in encode
    out_features = self.forward(features, **kwargs)
  File "C:\Users\Asus\Desktop\autofixer\autofixer-env\Lib\site-packages\sentence_transformers\SentenceTransformer.py", line 1133, in forward
    input = module(input, **module_kwargs)
  File "C:\Users\Asus\Desktop\autofixer\autofixer-env\Lib\site-packages\torch\nn\modules\module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "C:\Users\Asus\Desktop\autofixer\autofixer-env\Lib\site-packages\torch\nn\modules\module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "C:\Users\Asus\Desktop\autofixer\autofixer-env\Lib\site-packages\sentence_transformers\models\Transformer.py", line 437, in forward
    outputs = self.auto_model(**trans_features, **kwargs, return_dict=True)
  File "C:\Users\Asus\Desktop\autofixer\autofixer-env\Lib\site-packages\torch\nn\modules\module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "C:\Users\Asus\Desktop\autofixer\autofixer-env\Lib\site-packages\torch\nn\modules\module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "C:\Users\Asus\Desktop\autofixer\autofixer-env\Lib\site-packages\transformers\models\bert\modeling_bert.py", line 996, in forward
    encoder_outputs = self.encoder(
        embedding_output,
    ...<8 lines>...
        return_dict=return_dict,
    )
  File "C:\Users\Asus\Desktop\autofixer\autofixer-env\Lib\site-packages\torch\nn\modules\module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "C:\Users\Asus\Desktop\autofixer\autofixer-env\Lib\site-packages\torch\nn\modules\module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "C:\Users\Asus\Desktop\autofixer\autofixer-env\Lib\site-packages\transformers\models\bert\modeling_bert.py", line 651, in forward
    layer_outputs = layer_module(
        hidden_states,
    ...<5 lines>...
        output_attentions=output_attentions,
    )
  File "C:\Users\Asus\Desktop\autofixer\autofixer-env\Lib\site-packages\transformers\modeling_layers.py", line 83, in __call__
    return super().__call__(*args, **kwargs)
           ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "C:\Users\Asus\Desktop\autofixer\autofixer-env\Lib\site-packages\torch\nn\modules\module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "C:\Users\Asus\Desktop\autofixer\autofixer-env\Lib\site-packages\torch\nn\modules\module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "C:\Users\Asus\Desktop\autofixer\autofixer-env\Lib\site-packages\transformers\models\bert\modeling_bert.py", line 553, in forward
    self_attention_outputs = self.attention(
        hidden_states,
    ...<3 lines>...
        past_key_value=self_attn_past_key_value,
    )
  File "C:\Users\Asus\Desktop\autofixer\autofixer-env\Lib\site-packages\torch\nn\modules\module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "C:\Users\Asus\Desktop\autofixer\autofixer-env\Lib\site-packages\torch\nn\modules\module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "C:\Users\Asus\Desktop\autofixer\autofixer-env\Lib\site-packages\transformers\models\bert\modeling_bert.py", line 483, in forward
    self_outputs = self.self(
        hidden_states,
    ...<5 lines>...
        output_attentions,
    )
  File "C:\Users\Asus\Desktop\autofixer\autofixer-env\Lib\site-packages\torch\nn\modules\module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "C:\Users\Asus\Desktop\autofixer\autofixer-env\Lib\site-packages\torch\nn\modules\module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "C:\Users\Asus\Desktop\autofixer\autofixer-env\Lib\site-packages\transformers\models\bert\modeling_bert.py", line 377, in forward
    value_layer = self.transpose_for_scores(self.value(current_states))
                                            ~~~~~~~~~~^^^^^^^^^^^^^^^^
  File "C:\Users\Asus\Desktop\autofixer\autofixer-env\Lib\site-packages\torch\nn\modules\module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "C:\Users\Asus\Desktop\autofixer\autofixer-env\Lib\site-packages\torch\nn\modules\module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "C:\Users\Asus\Desktop\autofixer\autofixer-env\Lib\site-packages\torch\nn\modules\linear.py", line 125, in forward
    return F.linear(input, self.weight, self.bias)
           ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt
(autofixer-env) PS C:\Users\Asus\Desktop\autofixer> python embed_function.py
>>
 Indexed 6 functions from the folder.

 Results for query: 'save user preferences'

1. Function Name: save_preferences
 File: C:\Users\Asus\Desktop\autofixer\sample.py
 Lines: 5–7
 Docstring: No docstring

def save_preferences(prefs):
    with open("prefs.json", "w") as f:
        json.dump(prefs, f)
——————————————————————————————————————————————————
2. Function Name: embed_and_store
 File: C:\Users\Asus\Desktop\autofixer\embed_function.py
 Lines: 58–76
 Docstring: No docstring

def embed_and_store(functions: List[Tuple[str, str, dict]]):
    global function_text, function_metadata

    for _, full_text, metadata in functions:
        function_text.append(full_text)
        function_metadata.append(metadata)

    vectors = model.encode(function_text, convert_to_tensor=False)
    vectors = np.array(vectors).astype("float32")
    vectors = normalize(vectors, axis=1)

    index = faiss.IndexFlatIP(vectors.shape[1])  # Cosine similarity
    index.add(vectors)

    faiss.write_index(index, 'function_index.index')
    with open('function_metadata.pkl', 'wb') as f:
        pickle.dump(function_metadata, f)

    print(f" Indexed {len(function_text)} functions from the folder.")
——————————————————————————————————————————————————
3. Function Name: greet
 File: C:\Users\Asus\Desktop\autofixer\sample.py
 Lines: 2–3
 Docstring: No docstring

def greet(name):
    print(f"Hello, {name}")
——————————————————————————————————————————————————
(autofixer-env) PS C:\Users\Asus\Desktop\autofixer> 